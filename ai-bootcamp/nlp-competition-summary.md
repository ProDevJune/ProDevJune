---
title: 'NLP ê²½ì§„ëŒ€íšŒ ê²°ê³¼ ë°œí‘œ - ëŒ€í™” ìš”ì•½ ëª¨ë¸ ê°œë°œ'
layout: page
icon: fas fa-comments
permalink: /ai-bootcamp/nlp-competition-summary/
toc: true
tags:
  - NLP
  - ìì—°ì–´ì²˜ë¦¬
  - ëŒ€í™”ìš”ì•½
  - KoBART
  - ê²½ì§„ëŒ€íšŒ
  - íŒ€í”„ë¡œì íŠ¸
  - BackTranslation
  - ROUGE
  - PyTorch
  - Transformers
  - AIë¶€íŠ¸ìº í”„
---

![NLP ê²½ì§„ëŒ€íšŒ](/assets/img/nlp-competition-header.png)

# ğŸ—£ï¸ NLP ê²½ì§„ëŒ€íšŒ ê²°ê³¼ ë°œí‘œ - ëŒ€í™” ìš”ì•½ ëª¨ë¸ ê°œë°œ

> **5ì¡° - í‹°ëŒ ëª¨ì•„ Tech**: "ê°ìì˜ ì‘ì€ ê¸°ìˆ ì´ ëª¨ì—¬ í˜ì„ ë°œíœ˜í•œë‹¤!"

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### ğŸ¯ ê²½ì§„ëŒ€íšŒ ì •ë³´
- **ì£¼ì œ**: Dialogue Summarization (ì¼ìƒ ëŒ€í™” ìš”ì•½)
- **ê¸°ê°„**: 2025.07.25 ~ 2025.08.06 (13ì¼ê°„)
- **ëª©í‘œ**: 249ê°œì˜ ëŒ€í™”ë¬¸ì— ëŒ€í•´ ê°ê° 1ê°œì˜ ìš”ì•½ë¬¸ ìƒì„±
- **í‰ê°€ì§€í‘œ**: ROUGE (ROUGE-1, ROUGE-2, ROUGE-L)
- **ë°ì´í„°ì…‹**: í•™êµ ìƒí™œ, ì§ì¥, ì¹˜ë£Œ, ì‡¼í•‘, ì—¬ê°€, ì—¬í–‰ ë“± ê´‘ë²”ìœ„í•œ ì¼ìƒ ëŒ€í™”

### ğŸ† ìµœì¢… ê²°ê³¼
- **ì¤‘ê°„ í‰ê°€**: 9íŒ€ ì¤‘ **3ìœ„**
- **ìµœì¢… í‰ê°€**: **5ìœ„** (ìˆœìœ„ í•˜ë½)
- **ìµœì¢… ROUGE ì ìˆ˜**: 45.58 (ëª©í‘œ 50ì  ë¯¸ë‹¬ì„±)

---

## ğŸ‘¥ íŒ€ ì†Œê°œ

### ğŸ”¸ íŒ€ì› êµ¬ì„± ë° ì—­í• 

| ì—­í•  | ì´ë¦„ | ì „ê³µ/ë°°ê²½ | ë‹´ë‹¹ ì—…ë¬´ |
|------|------|-----------|-----------|
| **íŒ€ì¥** | ì†¡ê·œí—Œ | RAG / ê²½ì˜ì •ë³´ | EDA, ë² ì´ìŠ¤ë¼ì¸ ì‘ì„±, ìë£Œì¡°ì‚¬ |
| **íŒ€ì›** | ì´ìƒí˜„ | AIì‘ìš©ë¶„ì•¼ì°¾ê¸° / ì¬ë£Œê³µí•™ | Dialogue-Summary ê°„ ìƒê´€ê´€ê³„ ë¶„ì„, ë°ì´í„° íŠ¹ì„± ì¶”ì¶œ |
| **íŒ€ì›** | ì´ì˜ì¤€ | MLOps / ì»´í“¨í„°ê³µí•™ | ìë™í™” êµ¬ì¶•, ë‹¤ì–‘í•œ ëª¨ë¸ ë° ì˜µì…˜ ì¡°í•© ì‹¤í—˜ |
| **íŒ€ì›** | ì¡°ì€ë³„ | ê³ ë¶„ìê³µí•™ê³¼ | íŠ¹ìˆ˜ í‘œí˜„ ì „ì²˜ë¦¬ ë° ë§ˆìŠ¤í‚¹ í† í°í™” |
| **íŒ€ì›** | í¸ì•„í˜„ | ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼ | ë°ì´í„° ì „ì²˜ë¦¬ ë° Optunaë¥¼ í†µí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ |

### ğŸ› ï¸ í˜‘ì—… ë„êµ¬ ë° ë°©ì‹

```mermaid
graph TD
    A[íšŒì˜ ë° ì•„ì´ë””ì–´ ê³µìœ ] --> B[Zoom & Slack]
    C[TO-DO & ë¬¸ì„œí™”] --> D[GitHub Issue & docs]
    E[ì‹¤í—˜ ì •ë¦¬] --> F[WandB & Notion]
    G[ì½”ë“œ ì‘ì„±] --> H[Claude Code, Gemini CLI, ChatGPT]
```

- **ì»¤ë®¤ë‹ˆì¼€ì´ì…˜**: Zoom, Slack
- **í”„ë¡œì íŠ¸ ê´€ë¦¬**: GitHub Issue, Notion
- **ì‹¤í—˜ ì¶”ì **: WandB
- **AI ì–´ì‹œìŠ¤í„´íŠ¸**: Claude Code, Gemini CLI, ChatGPT

---

## ğŸ”¬ ê¸°ìˆ ì  ì ‘ê·¼ ë°©ë²•

### 1ï¸âƒ£ ê°œë°œ í™˜ê²½ êµ¬ì¶•

```python
# ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë²„ì „
Python 3.11 (conda ê°€ìƒí™˜ê²½)
PyTorch 2.6.0
transformers 4.54.0
pytorch-lightning 2.5.2
rouge, rouge-score (í‰ê°€ metric)
wandb (ì‹¤í—˜ ê´€ë¦¬)
unsloth, gradio, evaluate (ì¶”ë¡ /ì„œë¹™/í‰ê°€)
pandas, numpy, tqdm (ë°ì´í„° ì²˜ë¦¬/ë¶„ì„)
kiwipiepy (í˜•íƒœì†Œ ë¶„ì„, í•œêµ­ì–´ ì „ì²˜ë¦¬)
```

### 2ï¸âƒ£ ë°ì´í„° ë¶„ì„ (EDA)

#### ğŸ“Š ëŒ€í™”ë¬¸ ë° ìš”ì•½ë¬¸ ê¸¸ì´ ë¶„í¬ ë¶„ì„

**ì£¼ìš” ë°œê²¬ì‚¬í•­:**
- **ëŒ€í™”ë¬¸ ê¸¸ì´**: train/val/test ëª¨ë‘ 100~600ìì— ì£¼ë¡œ ë¶„í¬
- **ìš”ì•½ë¬¸ ê¸¸ì´**: 
  - train/val: 40~100ìì— ì§‘ì¤‘
  - test: 80~150ì êµ¬ê°„ì— ë” ë§ì´ ë¶„í¬ (ìµœëŒ€ 400ì ì´ìƒ)
- **Test ë°ì´í„°ì˜ íŠ¹ì„±**: ì „ë°˜ì ìœ¼ë¡œ ë” ê¸´ ëŒ€í™”ë¬¸ê³¼ ìš”ì•½ë¬¸ í¬í•¨

#### ğŸ” í† í° ìˆ˜ ë¶„í¬ ë¶„ì„

```python
# ìš”ì•½ë¬¸ í† í° ìˆ˜ ë¶„í¬ íŠ¹ì„±
train/val: ì£¼ë¡œ 20~40 í† í°
test: 40~60 í† í°ì— ì§‘ì¤‘, 100ê°œ ì´ìƒ í† í°ë„ ì¼ë¶€ ì¡´ì¬
```

#### ğŸ“ˆ ëŒ€í™”ë¬¸-ìš”ì•½ë¬¸ ê¸¸ì´ ìƒê´€ê´€ê³„

- **Train/Val**: ìƒê´€ê³„ìˆ˜ 0.66, 0.64ë¡œ ìœ ì˜ë¯¸í•œ ê´€ê³„
- **Test**: ìœ ì˜ë¯¸í•œ ìƒê´€ê´€ê³„ ì—†ìŒ
- **ì‹œì‚¬ì **: Test ë°ì´í„°ì˜ íŠ¹ì„±ì´ Train/Valê³¼ ìƒì´í•¨

### 3ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬

#### ğŸ§¹ í…ìŠ¤íŠ¸ ì •ì œ

```python
def clean_text(text: str) -> str:
    # ì¤„ë°”ê¿ˆ í‘œí˜„ í†µì¼
    text = text.replace("\\n", "\n").replace("<br>", "\n")
    
    # íŠ¹ì´ ì¼€ì´ìŠ¤ ì²˜ë¦¬
    text = text.replace("ã…ã…", "ë‚˜ë„ í–‰ë³µí•´.")
    
    # ììŒ/ëª¨ìŒ ì•½ì–´ ì œê±° (ã…‹ã…‹, ã…‡ã…‹, ã…œã…œ ë“±)
    text = re.sub(r"\b[ã„±-ã…ã…-ã…£]{2,}\b", "", text)
    
    # ì¤‘ë³µ ê³µë°± ì œê±°
    text = re.sub(r"\s+", " ", text)
    
    return text.strip()
```

#### ğŸ”§ ì§€ì‹œí‘œí˜„ ë³´ì™„ ë° í”„ë¡¬í”„íŠ¸ ì¶”ê°€

- **ì§€ì‹œì–´ ì¹˜í™˜**: "ê·¸ ì‚¬ëŒ", "ì´ê²ƒ" ë“±ì„ ì§ì „ ë°œí™”ì ì •ë³´ë¡œ ëŒ€ì²´
- **ë©”íƒ€ì •ë³´ í”„ë¡¬í”„íŠ¸**: `#Topic#`, `#Dialogue#` ë“± special token ì—°ë™
- **BART í¬ë§· ë³€í™˜**: bos_token, eos_tokenì— ë§ê²Œ ì¸ì½”ë”/ë””ì½”ë” ì…ë ¥ êµ¬ì„±

### 4ï¸âƒ£ ë°ì´í„° ì¦ê°• (Back Translation)

#### ğŸŒ Solar APIë¥¼ í™œìš©í•œ ì—­ë²ˆì—­

```python
# í•œêµ­ì–´ â†’ ì˜ì–´ â†’ ì¼ë³¸ì–´ â†’ í•œêµ­ì–´ ìˆœì„œë¡œ Back Translation
def back_translate_pipeline(text):
    ko_to_en = translate_solar_api(text, "ko", "en")
    en_to_ja = translate_solar_api(ko_to_en, "en", "ja") 
    ja_to_ko = translate_solar_api(en_to_ja, "ja", "ko")
    return ja_to_ko
```

**ì¦ê°• íš¨ê³¼:**
- ê¸°ì¡´ ë°ì´í„°ì…‹ì„ 2ë°°ë¡œ í™•ì¥
- **ROUGE ì ìˆ˜ 1ì  ìƒìŠ¹** (44.62 â†’ 45.58)

#### ğŸ“‹ ì¦ê°• ì „í›„ ë¹„êµ

| êµ¬ë¶„ | ROUGE-1 | ROUGE-2 | ROUGE-L | ìµœì¢… ì ìˆ˜ |
|------|---------|---------|---------|-----------|
| **ì¦ê°• ì „** | 0.5486 | 0.3703 | 0.4794 | 47.277 |
| **ì¦ê°• í›„** | 0.5758 | 0.3824 | 0.4922 | 48.3465 |

### 5ï¸âƒ£ ëª¨ë¸ë§ (KoBART ê¸°ë°˜)

#### ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜

```python
# HuggingFace BartForConditionalGeneration í™œìš©
model_name = "digit82/kobart-summarization"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = BartForConditionalGeneration.from_pretrained(model_name)

# Special Token ì²˜ë¦¬
special_tokens = ["#Person1#", "#Person2#", "#PhoneNumber#", ...]
tokenizer.add_special_tokens({"additional_special_tokens": special_tokens})
model.resize_token_embeddings(len(tokenizer))
```

#### âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”

**ì£¼ìš” ì„¤ì •ê°’:**
- **Encoder max_length**: 512 (1026ë³´ë‹¤ ì„±ëŠ¥ ìš°ìˆ˜)
- **Decoder max_length**: 200 (ì •ë³´ ì†ì‹¤ ì—†ì´ ì¶©ë¶„í•œ ê¸¸ì´)
- **Beam Search**: num_beams=2 (ì„±ëŠ¥ê³¼ ì†ë„ì˜ ìµœì  ê· í˜•)

#### ğŸ” ëª¨ë¸ ì„±ëŠ¥ ì¸ì‚¬ì´íŠ¸

> **í•µì‹¬ ë°œê²¬**: ëŒ€í™”ë¬¸ ì•ë¶€ë¶„ ì¤‘ì‹¬ì˜ ì •ë³´ë§Œ í™œìš©í•˜ëŠ” ê²ƒì´ ìš”ì•½ ì„±ëŠ¥ì— ìœ ë¦¬

### 6ï¸âƒ£ ì¶”ë¡  ë° ì œì¶œ

#### ğŸ¯ ì¶”ë¡  íŒŒì´í”„ë¼ì¸

```python
with torch.no_grad():
    for item in tqdm(dataloader):
        generated_ids = model.generate(
            input_ids=item['input_ids'].to(device),
            attention_mask=item['attention_mask'].to(device),
            early_stopping=True,
            max_length=200,
            num_beams=2,
            length_penalty=1.0
        )
        result = tokenizer.decode(generated_ids[0], skip_special_tokens=True)
        summaries.append(result)
```

---

## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ë° í•™ìŠµ

### ğŸš« ë°ì´í„° ì „ì²˜ë¦¬ì˜ ì—­ì„¤

**ë¬¸ì œ ìƒí™©:**
- ë°ì´í„°ì—ì„œ `\n`, `<br>`, `...`, `ã…ã…` ë“± ì „ì²˜ë¦¬ê°€ í•„ìš”í•´ ë³´ì´ëŠ” ìš”ì†Œë“¤ ë°œê²¬
- ëŒ€ê´„í˜¸([])ë¡œ ê°ì‹¸ì§„ ë¬¸ì¥ë“¤ì˜ í™”ì ë¶„ë¦¬ í•„ìš”ì„± ì¸ì‹

**ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²°ê³¼:**
- ì „ì²˜ë¦¬ë¥¼ í• ìˆ˜ë¡ **ì„±ëŠ¥ì´ ì˜¤íˆë ¤ í•˜ë½**
- ì‚¬ëŒì´ ë³´ê¸°ì— ìì—°ìŠ¤ëŸ¬ìš´ ì „ì²˜ë¦¬ê°€ ëª¨ë¸ ì„±ëŠ¥ì—ëŠ” ë¶€ì •ì  ì˜í–¥

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**
> ë°ì´í„° ì¤‘ ì „ì²˜ë¦¬ í•´ì•¼í•  ë¶€ë¶„ë“¤ì´ ë³´ì´ì§€ë§Œ, ì „ì²˜ë¦¬ë¥¼ í• ìˆ˜ë¡ ì„±ëŠ¥ì´ ë–¨ì–´ì§. ëª¨ë¸ì´ ì›ë³¸ ë°ì´í„°ì˜ ë…¸ì´ì¦ˆë„ í•™ìŠµ ì •ë³´ë¡œ í™œìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •.

### ğŸ“ˆ ë°ì´í„° ì¦ê°•ì˜ íš¨ê³¼

**Back Translation ì„±ê³¼:**
- ë‹¨ìˆœí•œ ë°ì´í„° ì–‘ í™•ì¥ì„ ë„˜ì–´ì„  **ì§ˆì  ê°œì„  íš¨ê³¼**
- ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ í•™ìŠµìœ¼ë¡œ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
- **ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼ê°€ ë†’ì€ ì¦ê°• ê¸°ë²•**

### âš–ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì˜ êµí›ˆ

**ì˜ì™¸ì˜ ë°œê²¬:**
- ë°°ì¹˜ í¬ê¸°ë¥¼ í¬ê²Œ, patienceë¥¼ ê¸¸ê²Œ, decoder ê¸¸ì´ë¥¼ ì§§ê²Œ, beam depthë¥¼ ì¤„ì´ëŠ” ë“±ì˜ "ìµœì í™”"ê°€ ì‹¤ì œë¡œëŠ” í° ê°œì„  ì—†ìŒ
- **ë°ì´í„°ì…‹ ë° íƒœìŠ¤í¬ íŠ¹ì„±ì— ë§ëŠ” ì ì •/ë³´ìˆ˜ì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ë” ìš°ìˆ˜**

**ì‹¤ìš©ì  ì ‘ê·¼:**
- Encoder max_length: 512 (ëŒ€í™”ë¬¸ ì•ë¶€ë¶„ ì§‘ì¤‘)
- Decoder max_length: 200 (ì¶©ë¶„í•˜ë©´ì„œë„ ë¶ˆí•„ìš”í•œ ë¬¸ì¥ ë°©ì§€)
- Beam search: 2 (ì„±ëŠ¥ê³¼ ì†ë„ì˜ ê· í˜•ì )

---

## ğŸ“Š ìµœì¢… ê²°ê³¼ ë° ì„±ê³¼

### ğŸ… ë¦¬ë”ë³´ë“œ ê²°ê³¼

| í‰ê°€ ë‹¨ê³„ | ìˆœìœ„ | ì´ íŒ€ ìˆ˜ | ROUGE ì ìˆ˜ |
|----------|------|----------|------------|
| **ì¤‘ê°„ í‰ê°€** | 3ìœ„ | 9íŒ€ | 48.3465 |
| **ìµœì¢… í‰ê°€** | 5ìœ„ | 9íŒ€ | 45.5898 |

### ğŸ“ˆ ëª©í‘œ ë‹¬ì„±ë„

| ëª©í‘œ í•­ëª© | ë‹¬ì„±ë„ | ë¹„ê³  |
|-----------|--------|------|
| ëŒ€í™” ìš”ì•½ ëª¨ë¸ íŒŒì¸íŠœë‹ ë° ì‹¤ì „ íŒŒì´í”„ë¼ì¸ ê²½í—˜ | âœ… ì™„ë£Œ | KoBART ê¸°ë°˜ end-to-end íŒŒì´í”„ë¼ì¸ êµ¬ì¶• |
| ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ë° ë°ì´í„° ì •ì œ ê¸°ë²• ì‹¤í—˜ | âœ… ì™„ë£Œ | ì „ì²˜ë¦¬ ì—­ì„¤ í˜„ìƒ ë°œê²¬ |
| ì—­ë²ˆì—­ ê¸°ë°˜ ë°ì´í„° ì¦ê°• ì‹¤í—˜ | âœ… ì™„ë£Œ | 1ì  ì„±ëŠ¥ í–¥ìƒ ë‹¬ì„± |
| ROUGE ê¸°ë°˜ ì‹ ë¢°ì„± ìˆëŠ” í‰ê°€ ë° ê²€ì¦ ì „ëµ ìˆ˜ë¦½ | âœ… ì™„ë£Œ | ì²´ê³„ì ì¸ ì‹¤í—˜ ì¶”ì  |
| ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œ ê¸°ë°˜ ì²´ê³„ì  ì‹¤í—˜ | ğŸ”º ë¶€ë¶„ ë‹¬ì„± | ì‹œê°„ ì œì•½ìœ¼ë¡œ ì¼ë¶€ ì‹¤í—˜ ë¯¸ì™„ë£Œ |
| **ëª©í‘œ ì ìˆ˜: ROUGE í‰ê·  50 ì´ìƒ** | âŒ ë¯¸ë‹¬ì„± | **45.58ì  (ëª©í‘œ ëŒ€ë¹„ 4.42ì  ë¶€ì¡±)** |

---

## ğŸ¤” íšŒê³  ë° í•™ìŠµ

### ğŸ“ íŒ€ì›ë³„ ì†Œê°

#### ğŸ‘¤ ì†¡ê·œí—Œ (íŒ€ì¥)
> CV ê²½ì§„ëŒ€íšŒì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì½”ë“œë¥¼ ê°œì„ í•˜ëŠ” ë° ì‹œê°„ì„ ë§ì´ ì†Œìš”í•´ ìš”ì•½ task ë…¼ë¬¸ ì¡°ì‚¬ë¥¼ ë§ì´ í•˜ì§€ ëª»í•œ ê²ƒì´ ì•„ì‰½ë‹¤. DialogSum ë…¼ë¬¸ì— ê¸°ë°˜í•´ ê³„íšì€ ì˜ ìˆ˜ë¦½í–ˆì§€ë§Œ, ë˜ ì½”ë“œ ë•Œë¬¸ì— ê³„íšëŒ€ë¡œ í•˜ì§€ ëª»í–ˆë˜ ê²ƒ ê°™ë‹¤.

#### ğŸ‘¤ ì´ìƒí˜„
> ìš”ì•½ì´ë¼ëŠ” Taskë¥¼ ë”¥ëŸ¬ë‹ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ê¸°ë²•ì„ ê°•ì˜ë¡œ ë“£ê³  AIì˜ íƒ€ì‚°ì—…ì˜ ì ìš©ì´ë¼ëŠ” ì£¼ì œë¥¼ ê¹Šì´ ê³ ë¯¼í•  ìˆ˜ ìˆì—ˆë‹¤. 2ì¸ ëŒ€í™”ë¡ì—ì„œ ìš”ì•½ì„ ëŒì–´ë‚´ëŠ” Taskë€ ì¸ê°„ë§Œì´ ê°€ì§„ í•¨ì¶•ì  ì‚¬ê³ ë ¥ì˜ ê²°ê³¼ë¥¼ ë‹´ì•„ì•¼ í•˜ëŠ” ì£¼ì œë¼ ì‹¬ë„ìˆëŠ” ë¬¸ì œë¼ëŠ” ê±¸ ë°°ìš°ê²Œ ë˜ì—ˆë‹¤.

#### ğŸ‘¤ ì´ì˜ì¤€
> ìë™í™”ë¥¼ êµ¬ì¶•í•˜ì—¬ ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í•˜ë ¤ê³  í•˜ì˜€ìŠµë‹ˆë‹¤. ë‘ ëŒ€í˜• ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ì‹¤í—˜ì„ í•˜ë ¤ê³  ë©°ì¹ ì„ ê³ ìƒí•˜ë©´ì„œ í–ˆì§€ë§Œ, ëë‚´ Claude MCPê°€ í•´ê²° ëª»í•˜ëŠ” ë¶€ë¶„ì´ ìˆì–´ì„œ í•´ë‹¹ ì‘ì—…ì€ í¬ê¸°í•˜ê³ , ì¡°ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëœì‹œê°„ ê³µë“¤ì¸ ê²ƒì´ í—ˆì‚¬ê°€ ëœ ë¶€ë¶„ì´ ìˆì–´ì„œ ì•„ì‰½ìŠµë‹ˆë‹¤.

#### ğŸ‘¤ ì¡°ì€ë³„
> Solar APIë¡œ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ Back Translationì„ ì§ì ‘ ì‹¤í—˜í•´ë³´ë©´ì„œ, í”„ë¡¬í”„íŠ¸ì˜ ì‘ì€ ì°¨ì´ë§Œìœ¼ë¡œë„ ê²°ê³¼ í’ˆì§ˆì´ í¬ê²Œ ë‹¬ë¼ì§„ë‹¤ëŠ” ì ì„ ì‹¤ê°í–ˆë‹¤. ëª¨ë¸ì´ ë‹¤ì–‘í•œ ëŒ€í™”ì™€ ìš”ì•½ ë°ì´í„°ë¥¼ í•™ìŠµí•´ ìë™ìœ¼ë¡œ ìš”ì•½ì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ, ì •í™•í•˜ê³  êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ê°€ ì„±ëŠ¥ì— ë§¤ìš° ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ í™•ì¸í–ˆë‹¤.

#### ğŸ‘¤ í¸ì•„í˜„
> ì „ì²˜ë¦¬ë¥¼ í†µí•´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ê¸°ëŒ€í–ˆì§€ë§Œ, ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë–¨ì–´ì ¸ì„œ ì•„ì‰¬ì› ìŠµë‹ˆë‹¤. ì‚¬ëŒì´ ë³´ê¸°ì— ë” ìì—°ìŠ¤ëŸ½ë„ë¡ ì „ì²˜ë¦¬í•œ ê²Œ ì˜ëª»ëë˜ ê²ƒì¸ì§€, ì„±ëŠ¥ ì €í•˜ì˜ ì›ì¸ì´ ì•„ì§ë„ ì˜ë¬¸ì…ë‹ˆë‹¤. ìš°ë¦¬ íŒ€ì„ í¬í•¨í•œ ë‹¤ë¥¸ íŒ€ë“¤ë„ ë©˜í† ë§ ì´í›„ì— ê°‘ìê¸° ì¹˜ê³  ì˜¬ë¼ì™”ëŠ”ë°, í™•ì‹¤íˆ ë©˜í† ë§ì—ì„œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë§ì´ë“¤ ì–»ì–´ê°€ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.

### ğŸ¯ í”„ë¡œì íŠ¸ ì„±ê³¼ ì¢…í•©

#### âœ… ì˜í–ˆë˜ ì 

1. **ì²´ê³„ì ì¸ ì—­í•  ë¶„ë°°**: ê°ìì˜ ì „ë¬¸ì„±ì„ ì‚´ë¦° ì—…ë¬´ ë¶„ë‹´
2. **íš¨ê³¼ì ì¸ í˜‘ì—…**: TODO ë¦¬ìŠ¤íŠ¸ ì‘ì„± ë° ê²°ê³¼ ê¸°ë¡ ì²´ê³„í™”
3. **ê±´ì„¤ì ì¸ í† ë¡ **: ì˜ê²¬ ì¶©ëŒì„ í†µí•œ ì•„ì´ë””ì–´ ë°œì „
4. **ë©˜í† ë§ í™œìš©**: ì–‘ì§ˆì˜ ì •ë³´ íšë“ ë° ë‹¤ì–‘í•œ ì‹œë„ ì‹¤í–‰

#### ğŸ” ì•„ì‰¬ì› ë˜ ì 

1. **ì‹œê°„ ê´€ë¦¬**: ë§ˆì§€ë§‰ ë‚  ì‹œê°„ ë¶€ì¡±ìœ¼ë¡œ ì¶”ê°€ ì‹¤í—˜ ê¸°íšŒ ìƒì‹¤
2. **ì´ë¡ ì  ë°°ê²½**: ë…¼ë¬¸ ì¡°ì‚¬ ì‹œê°„ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ê¹Šì´ ìˆëŠ” ì ‘ê·¼ í•œê³„
3. **ê¸°ìˆ ì  ë„ì „**: ì¼ë¶€ ê³ ë„í™”ëœ ì‹¤í—˜ ë„êµ¬ í™œìš© ì‹¤íŒ¨

#### ğŸš€ í–¥í›„ ê³„íš

> ë‹¤ìŒì—ë„ ì´ëŸ° ëŒ€íšŒë¥¼ ì°¸ì—¬í•œë‹¤ë©´ ì´ë²ˆ ì¸ì‚¬ì´íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë” ë†’ì€ ì ìˆ˜ë¥¼ ë…¸ë ¤ë³´ê³  ì‹¶ë‹¤.

**ê°œì„  ë°©í–¥:**
1. **ì‚¬ì „ ì¤€ë¹„**: ê´€ë ¨ ë…¼ë¬¸ ë° ìµœì‹  ê¸°ë²• ì‚¬ì „ ì¡°ì‚¬
2. **ì‹œê°„ ë°°ë¶„**: ì‹¤í—˜ê³¼ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ì‹œê°„ í™•ë³´
3. **ë„êµ¬ ìˆ™ë ¨ë„**: í˜‘ì—… ë„êµ¬ ë° ì‹¤í—˜ í™˜ê²½ ì‚¬ì „ êµ¬ì¶•

---

## ğŸ”— ê´€ë ¨ ìë£Œ

### ğŸ“š ê¸°ìˆ  ìŠ¤íƒ

- **Framework**: PyTorch, Transformers, PyTorch Lightning
- **Model**: KoBART (digit82/kobart-summarization)
- **Data Augmentation**: Solar API (Back Translation)
- **Evaluation**: ROUGE-1, ROUGE-2, ROUGE-L
- **Collaboration**: GitHub, WandB, Notion, Zoom, Slack

### ğŸ› ï¸ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬

```python
transformers==4.54.0
pytorch-lightning==2.5.2
torch==2.6.0
rouge-score
wandb
kiwipiepy
pandas
numpy
```

### ğŸ“Š ìµœì¢… ì„±ëŠ¥ ì§€í‘œ

```python
Final ROUGE Scores:
â”œâ”€â”€ ROUGE-1: 0.5535
â”œâ”€â”€ ROUGE-2: 0.3487  
â”œâ”€â”€ ROUGE-L: 0.4654
â””â”€â”€ Final Score: 45.5898
```

---

## ğŸ’¬ ê²°ë¡ 

ì´ë²ˆ NLP ê²½ì§„ëŒ€íšŒë¥¼ í†µí•´ **ëŒ€í™” ìš”ì•½**ì´ë¼ëŠ” ë³µì¡í•œ ìì—°ì–´ì²˜ë¦¬ íƒœìŠ¤í¬ì— ëŒ€í•œ ì‹¤ì§ˆì ì¸ ê²½í—˜ì„ ìŒ“ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë°ì´í„° ì „ì²˜ë¦¬ì˜ ì—­ì„¤, ë°ì´í„° ì¦ê°•ì˜ íš¨ê³¼, ê·¸ë¦¬ê³  í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì˜ ì‹¤ìš©ì  ì ‘ê·¼ë²• ë“± **ì´ë¡ ê³¼ ì‹¤ë¬´ ì‚¬ì´ì˜ ê°„ê·¹**ì„ ì²´í—˜í•  ìˆ˜ ìˆëŠ” ê·€ì¤‘í•œ ê¸°íšŒì˜€ìŠµë‹ˆë‹¤.

ëª©í‘œ ì ìˆ˜ì—ëŠ” ë„ë‹¬í•˜ì§€ ëª»í–ˆì§€ë§Œ, **íŒ€ì›Œí¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì²´ê³„ì ì¸ ì‹¤í—˜ê³¼ ë¶„ì„**ì„ í†µí•´ NLP ëª¨ë¸ ê°œë°œì˜ ì „ ê³¼ì •ì„ ê²½í—˜í•˜ë©° ì‹¤ì§ˆì ì¸ ì„±ì¥ì„ ì´ë£° ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

> **"ê°ìì˜ ì‘ì€ ê¸°ìˆ ì´ ëª¨ì—¬ í˜ì„ ë°œíœ˜í•œë‹¤"** - ìš°ë¦¬ íŒ€ì˜ ìŠ¬ë¡œê±´ì²˜ëŸ¼, ë‹¤ì–‘í•œ ë°°ê²½ì˜ íŒ€ì›ë“¤ì´ í˜‘ë ¥í•˜ì—¬ í•˜ë‚˜ì˜ ëª©í‘œë¥¼ í–¥í•´ ë‚˜ì•„ê°€ëŠ” ê³¼ì •ì—ì„œ ì§„ì •í•œ í•™ìŠµì´ ì¼ì–´ë‚¬ìŠµë‹ˆë‹¤.

---

*ì´ í¬ìŠ¤íŠ¸ëŠ” Upstage AI Lab Natural Language Processing ì„¸ë¯¸ë‚˜ (2025.08.07) ë°œí‘œ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
