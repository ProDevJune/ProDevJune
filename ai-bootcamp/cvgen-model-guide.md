---
title: 'CV Gen ëª¨ë¸ ê°€ì´ë“œ'
layout: page
icon: fas fa-robot
permalink: /ai-bootcamp/cvgen-model-guide/
toc: true
tags:
  - CV Gen
  - ìƒì„±í˜•AI
  - Stable Diffusion
  - Text-to-Image
  - ControlNet
  - Diffusion Model
  - Computer Vision
---

# ğŸ§  CV Gen ëª¨ë¸ ê°€ì´ë“œ

## 1. ê°œìš” (Overview)

**CV Gen ëª¨ë¸**ì€ "Computer Vision Generation"ì˜ ì•½ìë¡œ, **ì´ë¯¸ì§€ ìƒì„± ë˜ëŠ” ë³€í™˜**ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ **ì»´í“¨í„° ë¹„ì „ ìƒì„±í˜• AI ëª¨ë¸**ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  
í…ìŠ¤íŠ¸ ì„¤ëª… ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„±ì´ë‚˜, ê¸°ì¡´ ì´ë¯¸ì§€ í¸ì§‘ ë“±ì—ì„œ ë‘ê°ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

---

## 2. í•µì‹¬ ê°œë… (Core Concepts)

### 2.1 Text-to-Image Generation
- ì…ë ¥: í…ìŠ¤íŠ¸
- ì¶œë ¥: í•´ë‹¹ ì„¤ëª…ì— ë§ëŠ” ì´ë¯¸ì§€
- í•µì‹¬ ê¸°ìˆ : CLIP, Diffusion

### 2.2 Latent Diffusion Models (LDM)
- ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ì••ì¶•ëœ ê³µê°„ì—ì„œ ìƒì„±  
- Stable Diffusionì´ ëŒ€í‘œ ì‚¬ë¡€

### 2.3 ì´ë¯¸ì§€ ë³€í™˜ ê¸°ë°˜ ìƒì„±
- ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ë³€í˜• (ì˜ˆ: ë‚® â†’ ë°¤, í‘ë°± â†’ ì»¬ëŸ¬)
- pix2pix, CycleGAN ë“± ì‚¬ìš©

### 2.4 ê³ ê¸‰ ì œì–´ ê¸°ìˆ 
- ControlNet: ì…ë ¥ ì¡°ê±´ ê¸°ë°˜ ì œì–´
- LoRA: ì†ŒëŸ‰ í•™ìŠµìœ¼ë¡œ ì„±ëŠ¥ ìœ ì§€

---

## 3. ì£¼ìš” ëª¨ë¸ ë¹„êµ

| ëª¨ë¸ | ê¸°ê´€ | ê¸°ìˆ  | íŠ¹ì§• |
|------|------|------|------|
| DALLÂ·E 2/3 | OpenAI | CLIP + Diffusion | ì •êµí•œ í…ìŠ¤íŠ¸ í•´ì„ |
| Stable Diffusion | Stability AI | LDM | ì˜¤í”ˆì†ŒìŠ¤, í™•ì¥ì„± |
| Imagen | Google | T5 + Diffusion | ê³ í’ˆì§ˆ ì¶œë ¥ |
| Midjourney | Midjourney Labs | ë¹„ê³µê°œ | ì˜ˆìˆ ì  í’ˆì§ˆ ìš°ìˆ˜ |
| ControlNet | Tencent | ì¡°ê±´ ê¸°ë°˜ ì œì–´ | ë‹¤ì–‘í•œ ì…ë ¥ ì œì–´ ê°€ëŠ¥ |

---

## 4. ì•„í‚¤í…ì²˜ ë° íŒŒì´í”„ë¼ì¸

```plaintext
[Text Input] â†’ [Text Encoder] â†’ [Conditioned Diffusion Model] â†’ [Decoder] â†’ [Output Image]
```

---

## 5. í•™ìŠµ ë°©ì‹

- Pretraining: í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìŒ ëŒ€ê·œëª¨ í•™ìŠµ
- Contrastive Learning: í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ë™ì‹œ ì„ë² ë”©
- Diffusion Training: ë…¸ì´ì¦ˆ ì œê±° ê¸°ë°˜ ìƒì„± í•™ìŠµ

---

## 6. ì£¼ìš” ì‘ìš©

| ë¶„ì•¼ | ì˜ˆì‹œ |
|------|------|
| ì½˜í…ì¸  ì œì‘ | ì›¹íˆ°, ì¸ë„¤ì¼ |
| íŒ¨ì…˜/ì¸í…Œë¦¬ì–´ | ì°©ìš© ì‹œë®¬, ê°€êµ¬ ë°°ì¹˜ |
| ì˜ë£Œ | í•©ì„± CT ìƒì„± |
| ê²Œì„/ë©”íƒ€ë²„ìŠ¤ | ìºë¦­í„° ìƒì„± |
| ììœ¨ì£¼í–‰ | ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ |

---

## 7. ì‹¤ì „ ì½”ë“œ ì˜ˆì‹œ

```python
from diffusers import StableDiffusionPipeline
import torch

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")
pipe.to("cuda")
prompt = "a futuristic city in cyberpunk style"
image = pipe(prompt).images[0]
image.save("cyberpunk_city.png")
```

---

## 8. ìµœì‹  ë™í–¥

- DALLÂ·E 3 + GPT ì—°ë™
- DreamBooth, LoRA í™•ì‚°
- ControlNet, SDXL, PhotoMaker
- Foundation Model í†µí•©

---

## 9. ì¥ë‹¨ì 

âœ… ì§ê´€ì ì¸ í”„ë¡¬í”„íŠ¸, ì°½ì‘ íš¨ìœ¨  
âŒ í¸í–¥, ìœ¤ë¦¬ ë¬¸ì œ, ì‹¤ì‚¬ í•œê³„

---

## 10. ì¶”ì²œ ìë£Œ

- ğŸ“„ ë…¼ë¬¸: Rombach et al. (2022) *Latent Diffusion Models*  
- ğŸ§ª ì½”ë“œ: https://github.com/CompVis/stable-diffusion  
- ğŸ“š ê°•ì˜: HuggingFace Course, FastCampus

---

## âœ… ìš”ì•½ ì •ë¦¬

- CV Genì€ ìƒì„±í˜• ë¹„ì „ ëª¨ë¸ì˜ í•µì‹¬
- Diffusion + í…ìŠ¤íŠ¸ ì¸ì‹ (CLIP) êµ¬ì¡°ê°€ í•µì‹¬
- ë‹¤ì–‘í•œ ëª¨ë¸ ë¹„êµ ë° ì‹¤ì „ ì½”ë“œ ìŠµë“ ì¤‘ìš”

---

## ğŸ”‘ í•µì‹¬ì–´

`CV Gen`, `Diffusion`, `Stable Diffusion`, `ControlNet`, `Text-to-Image`, `Latent Space`, `Prompt Engineering`

---

**ğŸ“ ì €ì¥ ê²½ë¡œ ì˜ˆì‹œ**:  
`/ComputerVision/GenAI/01_CV_Gen_ëª¨ë¸_ì™„ì „ì •ë³µ.md`
